{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "from allennlp.predictors.predictor import Predictor\r\n",
    "from datetime import datetime as dt\r\n",
    "from dateutil.relativedelta import *\r\n",
    "from tqdm import tqdm\r\n",
    "from fuzzywuzzy import fuzz\r\n",
    "from fuzzywuzzy import process\r\n",
    "import os\r\n",
    "import allennlp_models.tagging\r\n",
    "import spacy\r\n",
    "import re\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Load in the coreference resolution tool/object\r\n",
    "predictor = Predictor.from_path('https://storage.googleapis.com/allennlp-public-models/coref-spanbert-large-2021.03.10.tar.gz')\r\n",
    "nlp = spacy.load('en_core_web_sm')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Joshualevy\\Anaconda3\\envs\\pandastest\\lib\\site-packages\\allennlp\\tango\\__init__.py:17: UserWarning: AllenNLP Tango is an experimental API and parts of it might change or disappear every time we release a new version.\n",
      "  warnings.warn(\n",
      "2021-09-17 10:53:12,657 - INFO - allennlp.common.plugins - Plugin allennlp_models available\n",
      "2021-09-17 10:53:12,821 - INFO - allennlp.common.file_utils - cache of https://storage.googleapis.com/allennlp-public-models/coref-spanbert-large-2021.03.10.tar.gz is up-to-date\n",
      "2021-09-17 10:53:12,824 - INFO - allennlp.models.archival - loading archive file https://storage.googleapis.com/allennlp-public-models/coref-spanbert-large-2021.03.10.tar.gz from cache at C:\\Users\\Joshualevy\\.allennlp\\cache\\038f918d294bd1a45e3709dfb22af5277b0be8677f750a85748c39979ce0e549.b897bfe76a04a5f70d6e88762a4d819b4b8b90e45b31b8314e0a6a9630d3f213\n",
      "2021-09-17 10:53:12,827 - INFO - allennlp.models.archival - extracting archive file C:\\Users\\Joshualevy\\.allennlp\\cache\\038f918d294bd1a45e3709dfb22af5277b0be8677f750a85748c39979ce0e549.b897bfe76a04a5f70d6e88762a4d819b4b8b90e45b31b8314e0a6a9630d3f213 to temp dir C:\\Users\\JOSHUA~1\\AppData\\Local\\Temp\\tmpzlz3qh1b\n",
      "2021-09-17 10:53:27,450 - WARNING - allennlp.common.params - error loading _jsonnet (this is expected on Windows), treating C:\\Users\\JOSHUA~1\\AppData\\Local\\Temp\\tmpzlz3qh1b\\config.json as plain json\n",
      "2021-09-17 10:53:27,453 - INFO - allennlp.common.params - dataset_reader.type = coref\n",
      "2021-09-17 10:53:27,454 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2021-09-17 10:53:27,455 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2021-09-17 10:53:27,456 - INFO - allennlp.common.params - dataset_reader.manual_multiprocess_sharding = False\n",
      "2021-09-17 10:53:27,456 - INFO - allennlp.common.params - dataset_reader.max_span_width = 30\n",
      "2021-09-17 10:53:27,457 - INFO - allennlp.common.params - dataset_reader.token_indexers.type = ref\n",
      "2021-09-17 10:53:27,459 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = pretrained_transformer_mismatched\n",
      "2021-09-17 10:53:27,461 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = pretrained_transformer_mismatched\n",
      "2021-09-17 10:53:27,462 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0\n",
      "2021-09-17 10:53:27,463 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.model_name = SpanBERT/spanbert-large-cased\n",
      "2021-09-17 10:53:27,464 - INFO - allennlp.common.params - type = SpanBERT/spanbert-large-cased\n",
      "2021-09-17 10:53:27,464 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tags\n",
      "2021-09-17 10:53:27,465 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.max_length = 512\n",
      "2021-09-17 10:53:27,466 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.tokenizer_kwargs = None\n",
      "2021-09-17 10:53:29,321 - INFO - allennlp.common.params - dataset_reader.wordpiece_modeling_tokenizer = None\n",
      "2021-09-17 10:53:29,323 - INFO - allennlp.common.params - dataset_reader.max_sentences = 110\n",
      "2021-09-17 10:53:29,324 - INFO - allennlp.common.params - dataset_reader.remove_singleton_clusters = False\n",
      "2021-09-17 10:53:29,325 - INFO - allennlp.common.params - validation_dataset_reader.type = coref\n",
      "2021-09-17 10:53:29,326 - INFO - allennlp.common.params - validation_dataset_reader.max_instances = None\n",
      "2021-09-17 10:53:29,326 - INFO - allennlp.common.params - validation_dataset_reader.manual_distributed_sharding = False\n",
      "2021-09-17 10:53:29,328 - INFO - allennlp.common.params - validation_dataset_reader.manual_multiprocess_sharding = False\n",
      "2021-09-17 10:53:29,329 - INFO - allennlp.common.params - validation_dataset_reader.max_span_width = 30\n",
      "2021-09-17 10:53:29,330 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.type = ref\n",
      "2021-09-17 10:53:29,333 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.type = pretrained_transformer_mismatched\n",
      "2021-09-17 10:53:29,334 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.type = pretrained_transformer_mismatched\n",
      "2021-09-17 10:53:29,334 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.token_min_padding_length = 0\n",
      "2021-09-17 10:53:29,335 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.model_name = SpanBERT/spanbert-large-cased\n",
      "2021-09-17 10:53:29,337 - INFO - allennlp.common.params - type = SpanBERT/spanbert-large-cased\n",
      "2021-09-17 10:53:29,338 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.namespace = tags\n",
      "2021-09-17 10:53:29,339 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.max_length = 512\n",
      "2021-09-17 10:53:29,340 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.tokenizer_kwargs = None\n",
      "2021-09-17 10:53:29,342 - INFO - allennlp.common.params - validation_dataset_reader.wordpiece_modeling_tokenizer = None\n",
      "2021-09-17 10:53:29,343 - INFO - allennlp.common.params - validation_dataset_reader.max_sentences = None\n",
      "2021-09-17 10:53:29,343 - INFO - allennlp.common.params - validation_dataset_reader.remove_singleton_clusters = False\n",
      "2021-09-17 10:53:29,345 - INFO - allennlp.common.params - type = from_instances\n",
      "2021-09-17 10:53:29,345 - INFO - allennlp.data.vocabulary - Loading token dictionary from C:\\Users\\JOSHUA~1\\AppData\\Local\\Temp\\tmpzlz3qh1b\\vocabulary.\n",
      "2021-09-17 10:53:29,350 - INFO - allennlp.common.params - model.type = coref\n",
      "2021-09-17 10:53:29,352 - INFO - allennlp.common.params - model.regularizer = None\n",
      "2021-09-17 10:53:29,353 - INFO - allennlp.common.params - model.ddp_accelerator = None\n",
      "2021-09-17 10:53:29,354 - INFO - allennlp.common.params - model.text_field_embedder.type = ref\n",
      "2021-09-17 10:53:29,356 - INFO - allennlp.common.params - model.text_field_embedder.type = basic\n",
      "2021-09-17 10:53:29,357 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.type = ref\n",
      "2021-09-17 10:53:29,359 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = pretrained_transformer_mismatched\n",
      "2021-09-17 10:53:29,360 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = pretrained_transformer_mismatched\n",
      "2021-09-17 10:53:29,361 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.model_name = SpanBERT/spanbert-large-cased\n",
      "2021-09-17 10:53:29,362 - INFO - allennlp.common.params - type = SpanBERT/spanbert-large-cased\n",
      "2021-09-17 10:53:29,363 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.max_length = 512\n",
      "2021-09-17 10:53:29,364 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.train_parameters = True\n",
      "2021-09-17 10:53:29,364 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.last_layer_only = True\n",
      "2021-09-17 10:53:29,365 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_file = None\n",
      "2021-09-17 10:53:29,366 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_strip_prefix = None\n",
      "2021-09-17 10:53:29,367 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.load_weights = True\n",
      "2021-09-17 10:53:29,368 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.gradient_checkpointing = None\n",
      "2021-09-17 10:53:29,369 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.tokenizer_kwargs = None\n",
      "2021-09-17 10:53:29,369 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.transformer_kwargs = None\n",
      "2021-09-17 10:53:29,370 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.sub_token_mode = avg\n",
      "Some weights of BertModel were not initialized from the model checkpoint at SpanBERT/spanbert-large-cased and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2021-09-17 10:53:34,167 - INFO - allennlp.common.params - model.context_layer.type = pass_through\n",
      "2021-09-17 10:53:34,169 - INFO - allennlp.common.params - model.context_layer.type = pass_through\n",
      "2021-09-17 10:53:34,169 - INFO - allennlp.common.params - model.context_layer.input_dim = 1024\n",
      "2021-09-17 10:53:34,170 - INFO - allennlp.common.params - model.mention_feedforward.type = ref\n",
      "2021-09-17 10:53:34,172 - INFO - allennlp.common.params - model.mention_feedforward.input_dim = 3092\n",
      "2021-09-17 10:53:34,173 - INFO - allennlp.common.params - model.mention_feedforward.num_layers = 2\n",
      "2021-09-17 10:53:34,173 - INFO - allennlp.common.params - model.mention_feedforward.hidden_dims = 1500\n",
      "2021-09-17 10:53:34,174 - INFO - allennlp.common.params - model.mention_feedforward.activations = relu\n",
      "2021-09-17 10:53:34,174 - INFO - allennlp.common.params - type = relu\n",
      "2021-09-17 10:53:34,175 - INFO - allennlp.common.params - type = relu\n",
      "2021-09-17 10:53:34,176 - INFO - allennlp.common.params - type = relu\n",
      "2021-09-17 10:53:34,176 - INFO - allennlp.common.params - model.mention_feedforward.dropout = 0.3\n",
      "2021-09-17 10:53:34,234 - INFO - allennlp.common.params - model.antecedent_feedforward.type = ref\n",
      "2021-09-17 10:53:34,236 - INFO - allennlp.common.params - model.antecedent_feedforward.input_dim = 9296\n",
      "2021-09-17 10:53:34,237 - INFO - allennlp.common.params - model.antecedent_feedforward.num_layers = 2\n",
      "2021-09-17 10:53:34,238 - INFO - allennlp.common.params - model.antecedent_feedforward.hidden_dims = 1500\n",
      "2021-09-17 10:53:34,238 - INFO - allennlp.common.params - model.antecedent_feedforward.activations = relu\n",
      "2021-09-17 10:53:34,239 - INFO - allennlp.common.params - type = relu\n",
      "2021-09-17 10:53:34,239 - INFO - allennlp.common.params - type = relu\n",
      "2021-09-17 10:53:34,240 - INFO - allennlp.common.params - type = relu\n",
      "2021-09-17 10:53:34,240 - INFO - allennlp.common.params - model.antecedent_feedforward.dropout = 0.3\n",
      "2021-09-17 10:53:34,364 - INFO - allennlp.common.params - model.feature_size = 20\n",
      "2021-09-17 10:53:34,365 - INFO - allennlp.common.params - model.max_span_width = 30\n",
      "2021-09-17 10:53:34,365 - INFO - allennlp.common.params - model.spans_per_word = 0.4\n",
      "2021-09-17 10:53:34,366 - INFO - allennlp.common.params - model.max_antecedents = 50\n",
      "2021-09-17 10:53:34,367 - INFO - allennlp.common.params - model.coarse_to_fine = True\n",
      "2021-09-17 10:53:34,368 - INFO - allennlp.common.params - model.inference_order = 2\n",
      "2021-09-17 10:53:34,368 - INFO - allennlp.common.params - model.lexical_dropout = 0.2\n",
      "2021-09-17 10:53:34,369 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x000002024EB6FE50>\n",
      "2021-09-17 10:53:34,420 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2021-09-17 10:53:34,422 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2021-09-17 10:53:34,423 - INFO - allennlp.nn.initializers -    _antecedent_feedforward._module._linear_layers.0.bias\n",
      "2021-09-17 10:53:34,424 - INFO - allennlp.nn.initializers -    _antecedent_feedforward._module._linear_layers.0.weight\n",
      "2021-09-17 10:53:34,424 - INFO - allennlp.nn.initializers -    _antecedent_feedforward._module._linear_layers.1.bias\n",
      "2021-09-17 10:53:34,425 - INFO - allennlp.nn.initializers -    _antecedent_feedforward._module._linear_layers.1.weight\n",
      "2021-09-17 10:53:34,425 - INFO - allennlp.nn.initializers -    _antecedent_scorer._module.bias\n",
      "2021-09-17 10:53:34,426 - INFO - allennlp.nn.initializers -    _antecedent_scorer._module.weight\n",
      "2021-09-17 10:53:34,427 - INFO - allennlp.nn.initializers -    _attentive_span_extractor._global_attention._module.bias\n",
      "2021-09-17 10:53:34,428 - INFO - allennlp.nn.initializers -    _attentive_span_extractor._global_attention._module.weight\n",
      "2021-09-17 10:53:34,428 - INFO - allennlp.nn.initializers -    _coarse2fine_scorer.bias\n",
      "2021-09-17 10:53:34,429 - INFO - allennlp.nn.initializers -    _coarse2fine_scorer.weight\n",
      "2021-09-17 10:53:34,430 - INFO - allennlp.nn.initializers -    _distance_embedding.weight\n",
      "2021-09-17 10:53:34,430 - INFO - allennlp.nn.initializers -    _endpoint_span_extractor._span_width_embedding.weight\n",
      "2021-09-17 10:53:34,431 - INFO - allennlp.nn.initializers -    _mention_feedforward._module._linear_layers.0.bias\n",
      "2021-09-17 10:53:34,432 - INFO - allennlp.nn.initializers -    _mention_feedforward._module._linear_layers.0.weight\n",
      "2021-09-17 10:53:34,432 - INFO - allennlp.nn.initializers -    _mention_feedforward._module._linear_layers.1.bias\n",
      "2021-09-17 10:53:34,433 - INFO - allennlp.nn.initializers -    _mention_feedforward._module._linear_layers.1.weight\n",
      "2021-09-17 10:53:34,434 - INFO - allennlp.nn.initializers -    _mention_scorer._module.bias\n",
      "2021-09-17 10:53:34,434 - INFO - allennlp.nn.initializers -    _mention_scorer._module.weight\n",
      "2021-09-17 10:53:34,435 - INFO - allennlp.nn.initializers -    _span_updating_gated_sum._gate.bias\n",
      "2021-09-17 10:53:34,436 - INFO - allennlp.nn.initializers -    _span_updating_gated_sum._gate.weight\n",
      "2021-09-17 10:53:34,436 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.LayerNorm.bias\n",
      "2021-09-17 10:53:34,437 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.LayerNorm.weight\n",
      "2021-09-17 10:53:34,438 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.position_embeddings.weight\n",
      "2021-09-17 10:53:34,439 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight\n",
      "2021-09-17 10:53:34,439 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.word_embeddings.weight\n",
      "2021-09-17 10:53:34,440 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,441 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,441 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias\n",
      "2021-09-17 10:53:34,442 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight\n",
      "2021-09-17 10:53:34,443 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias\n",
      "2021-09-17 10:53:34,444 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight\n",
      "2021-09-17 10:53:34,445 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias\n",
      "2021-09-17 10:53:34,445 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight\n",
      "2021-09-17 10:53:34,446 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias\n",
      "2021-09-17 10:53:34,447 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight\n",
      "2021-09-17 10:53:34,448 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias\n",
      "2021-09-17 10:53:34,449 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight\n",
      "2021-09-17 10:53:34,451 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,452 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,452 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias\n",
      "2021-09-17 10:53:34,453 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight\n",
      "2021-09-17 10:53:34,453 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,454 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias\n",
      "2021-09-17 10:53:34,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight\n",
      "2021-09-17 10:53:34,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias\n",
      "2021-09-17 10:53:34,456 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight\n",
      "2021-09-17 10:53:34,456 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias\n",
      "2021-09-17 10:53:34,457 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight\n",
      "2021-09-17 10:53:34,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias\n",
      "2021-09-17 10:53:34,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight\n",
      "2021-09-17 10:53:34,459 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias\n",
      "2021-09-17 10:53:34,460 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight\n",
      "2021-09-17 10:53:34,461 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,462 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,462 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias\n",
      "2021-09-17 10:53:34,463 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight\n",
      "2021-09-17 10:53:34,463 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,464 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,464 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias\n",
      "2021-09-17 10:53:34,467 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight\n",
      "2021-09-17 10:53:34,469 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias\n",
      "2021-09-17 10:53:34,469 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight\n",
      "2021-09-17 10:53:34,470 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias\n",
      "2021-09-17 10:53:34,471 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight\n",
      "2021-09-17 10:53:34,471 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias\n",
      "2021-09-17 10:53:34,472 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight\n",
      "2021-09-17 10:53:34,472 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias\n",
      "2021-09-17 10:53:34,472 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight\n",
      "2021-09-17 10:53:34,473 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,473 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,477 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias\n",
      "2021-09-17 10:53:34,478 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight\n",
      "2021-09-17 10:53:34,479 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,480 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,482 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias\n",
      "2021-09-17 10:53:34,482 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight\n",
      "2021-09-17 10:53:34,483 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias\n",
      "2021-09-17 10:53:34,484 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight\n",
      "2021-09-17 10:53:34,484 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias\n",
      "2021-09-17 10:53:34,485 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight\n",
      "2021-09-17 10:53:34,485 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias\n",
      "2021-09-17 10:53:34,485 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight\n",
      "2021-09-17 10:53:34,486 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias\n",
      "2021-09-17 10:53:34,487 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight\n",
      "2021-09-17 10:53:34,487 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,488 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,488 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias\n",
      "2021-09-17 10:53:34,489 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight\n",
      "2021-09-17 10:53:34,490 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,490 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,491 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.output.dense.bias\n",
      "2021-09-17 10:53:34,491 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.output.dense.weight\n",
      "2021-09-17 10:53:34,492 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.self.key.bias\n",
      "2021-09-17 10:53:34,492 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.self.key.weight\n",
      "2021-09-17 10:53:34,493 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.self.query.bias\n",
      "2021-09-17 10:53:34,493 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.self.query.weight\n",
      "2021-09-17 10:53:34,494 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.self.value.bias\n",
      "2021-09-17 10:53:34,495 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.self.value.weight\n",
      "2021-09-17 10:53:34,496 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.intermediate.dense.bias\n",
      "2021-09-17 10:53:34,496 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.intermediate.dense.weight\n",
      "2021-09-17 10:53:34,498 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,499 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,499 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.output.dense.bias\n",
      "2021-09-17 10:53:34,499 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.output.dense.weight\n",
      "2021-09-17 10:53:34,500 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,501 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,501 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.output.dense.bias\n",
      "2021-09-17 10:53:34,502 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.output.dense.weight\n",
      "2021-09-17 10:53:34,502 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.self.key.bias\n",
      "2021-09-17 10:53:34,503 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.self.key.weight\n",
      "2021-09-17 10:53:34,504 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.self.query.bias\n",
      "2021-09-17 10:53:34,504 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.self.query.weight\n",
      "2021-09-17 10:53:34,505 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.self.value.bias\n",
      "2021-09-17 10:53:34,506 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.self.value.weight\n",
      "2021-09-17 10:53:34,506 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.intermediate.dense.bias\n",
      "2021-09-17 10:53:34,507 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.intermediate.dense.weight\n",
      "2021-09-17 10:53:34,508 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,510 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,511 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.output.dense.bias\n",
      "2021-09-17 10:53:34,513 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.output.dense.weight\n",
      "2021-09-17 10:53:34,513 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,514 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,514 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.output.dense.bias\n",
      "2021-09-17 10:53:34,515 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.output.dense.weight\n",
      "2021-09-17 10:53:34,516 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.self.key.bias\n",
      "2021-09-17 10:53:34,516 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.self.key.weight\n",
      "2021-09-17 10:53:34,517 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.self.query.bias\n",
      "2021-09-17 10:53:34,518 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.self.query.weight\n",
      "2021-09-17 10:53:34,519 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.self.value.bias\n",
      "2021-09-17 10:53:34,519 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.self.value.weight\n",
      "2021-09-17 10:53:34,520 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.intermediate.dense.bias\n",
      "2021-09-17 10:53:34,521 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.intermediate.dense.weight\n",
      "2021-09-17 10:53:34,521 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,522 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,523 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.output.dense.bias\n",
      "2021-09-17 10:53:34,523 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.output.dense.weight\n",
      "2021-09-17 10:53:34,524 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,524 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,525 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.output.dense.bias\n",
      "2021-09-17 10:53:34,526 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.output.dense.weight\n",
      "2021-09-17 10:53:34,526 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.self.key.bias\n",
      "2021-09-17 10:53:34,526 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.self.key.weight\n",
      "2021-09-17 10:53:34,527 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.self.query.bias\n",
      "2021-09-17 10:53:34,527 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.self.query.weight\n",
      "2021-09-17 10:53:34,528 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.self.value.bias\n",
      "2021-09-17 10:53:34,529 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.self.value.weight\n",
      "2021-09-17 10:53:34,529 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.intermediate.dense.bias\n",
      "2021-09-17 10:53:34,529 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.intermediate.dense.weight\n",
      "2021-09-17 10:53:34,530 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,530 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,530 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.output.dense.bias\n",
      "2021-09-17 10:53:34,531 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.output.dense.weight\n",
      "2021-09-17 10:53:34,531 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,531 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,533 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.output.dense.bias\n",
      "2021-09-17 10:53:34,533 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.output.dense.weight\n",
      "2021-09-17 10:53:34,533 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.self.key.bias\n",
      "2021-09-17 10:53:34,534 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.self.key.weight\n",
      "2021-09-17 10:53:34,534 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.self.query.bias\n",
      "2021-09-17 10:53:34,535 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.self.query.weight\n",
      "2021-09-17 10:53:34,535 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.self.value.bias\n",
      "2021-09-17 10:53:34,535 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.self.value.weight\n",
      "2021-09-17 10:53:34,536 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.intermediate.dense.bias\n",
      "2021-09-17 10:53:34,536 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.intermediate.dense.weight\n",
      "2021-09-17 10:53:34,537 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,537 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,538 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.output.dense.bias\n",
      "2021-09-17 10:53:34,538 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.output.dense.weight\n",
      "2021-09-17 10:53:34,539 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,539 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,540 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.output.dense.bias\n",
      "2021-09-17 10:53:34,540 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.output.dense.weight\n",
      "2021-09-17 10:53:34,541 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.self.key.bias\n",
      "2021-09-17 10:53:34,541 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.self.key.weight\n",
      "2021-09-17 10:53:34,542 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.self.query.bias\n",
      "2021-09-17 10:53:34,542 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.self.query.weight\n",
      "2021-09-17 10:53:34,543 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.self.value.bias\n",
      "2021-09-17 10:53:34,543 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.self.value.weight\n",
      "2021-09-17 10:53:34,544 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.intermediate.dense.bias\n",
      "2021-09-17 10:53:34,544 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.intermediate.dense.weight\n",
      "2021-09-17 10:53:34,545 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,545 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,545 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.output.dense.bias\n",
      "2021-09-17 10:53:34,546 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.output.dense.weight\n",
      "2021-09-17 10:53:34,547 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,547 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,548 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.output.dense.bias\n",
      "2021-09-17 10:53:34,548 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.output.dense.weight\n",
      "2021-09-17 10:53:34,549 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.self.key.bias\n",
      "2021-09-17 10:53:34,549 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.self.key.weight\n",
      "2021-09-17 10:53:34,550 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.self.query.bias\n",
      "2021-09-17 10:53:34,550 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.self.query.weight\n",
      "2021-09-17 10:53:34,550 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.self.value.bias\n",
      "2021-09-17 10:53:34,551 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.self.value.weight\n",
      "2021-09-17 10:53:34,551 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.intermediate.dense.bias\n",
      "2021-09-17 10:53:34,552 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.intermediate.dense.weight\n",
      "2021-09-17 10:53:34,552 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,553 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,553 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.output.dense.bias\n",
      "2021-09-17 10:53:34,553 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.output.dense.weight\n",
      "2021-09-17 10:53:34,554 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,555 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,555 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.output.dense.bias\n",
      "2021-09-17 10:53:34,556 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.output.dense.weight\n",
      "2021-09-17 10:53:34,556 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.self.key.bias\n",
      "2021-09-17 10:53:34,557 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.self.key.weight\n",
      "2021-09-17 10:53:34,557 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.self.query.bias\n",
      "2021-09-17 10:53:34,558 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.self.query.weight\n",
      "2021-09-17 10:53:34,558 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.self.value.bias\n",
      "2021-09-17 10:53:34,559 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.self.value.weight\n",
      "2021-09-17 10:53:34,559 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.intermediate.dense.bias\n",
      "2021-09-17 10:53:34,560 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.intermediate.dense.weight\n",
      "2021-09-17 10:53:34,560 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,561 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,561 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.output.dense.bias\n",
      "2021-09-17 10:53:34,562 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.output.dense.weight\n",
      "2021-09-17 10:53:34,562 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,564 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,564 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias\n",
      "2021-09-17 10:53:34,565 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight\n",
      "2021-09-17 10:53:34,565 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias\n",
      "2021-09-17 10:53:34,565 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight\n",
      "2021-09-17 10:53:34,566 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias\n",
      "2021-09-17 10:53:34,566 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight\n",
      "2021-09-17 10:53:34,566 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias\n",
      "2021-09-17 10:53:34,567 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight\n",
      "2021-09-17 10:53:34,568 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias\n",
      "2021-09-17 10:53:34,568 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight\n",
      "2021-09-17 10:53:34,569 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,569 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,570 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias\n",
      "2021-09-17 10:53:34,570 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight\n",
      "2021-09-17 10:53:34,570 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,571 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,571 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.output.dense.bias\n",
      "2021-09-17 10:53:34,573 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.output.dense.weight\n",
      "2021-09-17 10:53:34,573 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.self.key.bias\n",
      "2021-09-17 10:53:34,574 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.self.key.weight\n",
      "2021-09-17 10:53:34,574 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.self.query.bias\n",
      "2021-09-17 10:53:34,574 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.self.query.weight\n",
      "2021-09-17 10:53:34,575 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.self.value.bias\n",
      "2021-09-17 10:53:34,576 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.self.value.weight\n",
      "2021-09-17 10:53:34,576 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.intermediate.dense.bias\n",
      "2021-09-17 10:53:34,577 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.intermediate.dense.weight\n",
      "2021-09-17 10:53:34,577 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,578 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,578 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.output.dense.bias\n",
      "2021-09-17 10:53:34,579 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.output.dense.weight\n",
      "2021-09-17 10:53:34,579 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,579 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,580 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.output.dense.bias\n",
      "2021-09-17 10:53:34,580 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.output.dense.weight\n",
      "2021-09-17 10:53:34,581 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.self.key.bias\n",
      "2021-09-17 10:53:34,582 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.self.key.weight\n",
      "2021-09-17 10:53:34,582 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.self.query.bias\n",
      "2021-09-17 10:53:34,583 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.self.query.weight\n",
      "2021-09-17 10:53:34,583 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.self.value.bias\n",
      "2021-09-17 10:53:34,583 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.self.value.weight\n",
      "2021-09-17 10:53:34,583 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.intermediate.dense.bias\n",
      "2021-09-17 10:53:34,584 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.intermediate.dense.weight\n",
      "2021-09-17 10:53:34,584 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,585 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,585 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.output.dense.bias\n",
      "2021-09-17 10:53:34,585 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.output.dense.weight\n",
      "2021-09-17 10:53:34,586 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,586 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,586 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.output.dense.bias\n",
      "2021-09-17 10:53:34,587 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.output.dense.weight\n",
      "2021-09-17 10:53:34,587 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.self.key.bias\n",
      "2021-09-17 10:53:34,588 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.self.key.weight\n",
      "2021-09-17 10:53:34,588 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.self.query.bias\n",
      "2021-09-17 10:53:34,588 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.self.query.weight\n",
      "2021-09-17 10:53:34,589 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.self.value.bias\n",
      "2021-09-17 10:53:34,591 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.self.value.weight\n",
      "2021-09-17 10:53:34,591 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.intermediate.dense.bias\n",
      "2021-09-17 10:53:34,591 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.intermediate.dense.weight\n",
      "2021-09-17 10:53:34,592 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,592 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,593 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.output.dense.bias\n",
      "2021-09-17 10:53:34,594 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.output.dense.weight\n",
      "2021-09-17 10:53:34,594 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,595 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,595 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.output.dense.bias\n",
      "2021-09-17 10:53:34,596 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.output.dense.weight\n",
      "2021-09-17 10:53:34,596 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.self.key.bias\n",
      "2021-09-17 10:53:34,597 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.self.key.weight\n",
      "2021-09-17 10:53:34,598 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.self.query.bias\n",
      "2021-09-17 10:53:34,598 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.self.query.weight\n",
      "2021-09-17 10:53:34,599 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.self.value.bias\n",
      "2021-09-17 10:53:34,599 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.self.value.weight\n",
      "2021-09-17 10:53:34,600 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.intermediate.dense.bias\n",
      "2021-09-17 10:53:34,600 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.intermediate.dense.weight\n",
      "2021-09-17 10:53:34,600 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,601 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,601 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.output.dense.bias\n",
      "2021-09-17 10:53:34,602 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.output.dense.weight\n",
      "2021-09-17 10:53:34,603 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,603 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,603 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias\n",
      "2021-09-17 10:53:34,604 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight\n",
      "2021-09-17 10:53:34,604 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias\n",
      "2021-09-17 10:53:34,604 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight\n",
      "2021-09-17 10:53:34,605 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias\n",
      "2021-09-17 10:53:34,606 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight\n",
      "2021-09-17 10:53:34,607 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias\n",
      "2021-09-17 10:53:34,607 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight\n",
      "2021-09-17 10:53:34,608 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias\n",
      "2021-09-17 10:53:34,609 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight\n",
      "2021-09-17 10:53:34,609 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,610 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,610 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias\n",
      "2021-09-17 10:53:34,611 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight\n",
      "2021-09-17 10:53:34,611 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,612 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,612 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias\n",
      "2021-09-17 10:53:34,613 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight\n",
      "2021-09-17 10:53:34,614 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias\n",
      "2021-09-17 10:53:34,614 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight\n",
      "2021-09-17 10:53:34,614 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias\n",
      "2021-09-17 10:53:34,615 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight\n",
      "2021-09-17 10:53:34,615 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias\n",
      "2021-09-17 10:53:34,616 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight\n",
      "2021-09-17 10:53:34,616 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias\n",
      "2021-09-17 10:53:34,617 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight\n",
      "2021-09-17 10:53:34,617 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,617 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,618 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias\n",
      "2021-09-17 10:53:34,618 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight\n",
      "2021-09-17 10:53:34,618 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,619 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,619 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias\n",
      "2021-09-17 10:53:34,620 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight\n",
      "2021-09-17 10:53:34,620 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias\n",
      "2021-09-17 10:53:34,620 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight\n",
      "2021-09-17 10:53:34,621 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias\n",
      "2021-09-17 10:53:34,621 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight\n",
      "2021-09-17 10:53:34,622 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias\n",
      "2021-09-17 10:53:34,623 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight\n",
      "2021-09-17 10:53:34,623 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias\n",
      "2021-09-17 10:53:34,624 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight\n",
      "2021-09-17 10:53:34,624 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,625 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,626 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias\n",
      "2021-09-17 10:53:34,626 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight\n",
      "2021-09-17 10:53:34,626 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,627 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,628 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias\n",
      "2021-09-17 10:53:34,629 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight\n",
      "2021-09-17 10:53:34,630 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias\n",
      "2021-09-17 10:53:34,631 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight\n",
      "2021-09-17 10:53:34,631 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias\n",
      "2021-09-17 10:53:34,632 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight\n",
      "2021-09-17 10:53:34,633 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias\n",
      "2021-09-17 10:53:34,633 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight\n",
      "2021-09-17 10:53:34,635 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias\n",
      "2021-09-17 10:53:34,635 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight\n",
      "2021-09-17 10:53:34,636 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,636 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,637 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias\n",
      "2021-09-17 10:53:34,637 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight\n",
      "2021-09-17 10:53:34,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias\n",
      "2021-09-17 10:53:34,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight\n",
      "2021-09-17 10:53:34,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias\n",
      "2021-09-17 10:53:34,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight\n",
      "2021-09-17 10:53:34,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias\n",
      "2021-09-17 10:53:34,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight\n",
      "2021-09-17 10:53:34,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias\n",
      "2021-09-17 10:53:34,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight\n",
      "2021-09-17 10:53:34,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias\n",
      "2021-09-17 10:53:34,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight\n",
      "2021-09-17 10:53:34,649 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,649 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,650 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias\n",
      "2021-09-17 10:53:34,651 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight\n",
      "2021-09-17 10:53:34,652 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,652 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,653 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias\n",
      "2021-09-17 10:53:34,654 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight\n",
      "2021-09-17 10:53:34,654 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias\n",
      "2021-09-17 10:53:34,655 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight\n",
      "2021-09-17 10:53:34,656 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias\n",
      "2021-09-17 10:53:34,656 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight\n",
      "2021-09-17 10:53:34,657 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias\n",
      "2021-09-17 10:53:34,658 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight\n",
      "2021-09-17 10:53:34,659 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias\n",
      "2021-09-17 10:53:34,660 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight\n",
      "2021-09-17 10:53:34,661 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,662 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,664 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias\n",
      "2021-09-17 10:53:34,665 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight\n",
      "2021-09-17 10:53:34,665 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,666 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,666 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias\n",
      "2021-09-17 10:53:34,667 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight\n",
      "2021-09-17 10:53:34,668 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias\n",
      "2021-09-17 10:53:34,668 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight\n",
      "2021-09-17 10:53:34,669 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias\n",
      "2021-09-17 10:53:34,669 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight\n",
      "2021-09-17 10:53:34,669 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias\n",
      "2021-09-17 10:53:34,670 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight\n",
      "2021-09-17 10:53:34,670 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias\n",
      "2021-09-17 10:53:34,671 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight\n",
      "2021-09-17 10:53:34,671 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias\n",
      "2021-09-17 10:53:34,672 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight\n",
      "2021-09-17 10:53:34,672 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias\n",
      "2021-09-17 10:53:34,672 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight\n",
      "2021-09-17 10:53:34,673 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.pooler.dense.bias\n",
      "2021-09-17 10:53:34,673 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.pooler.dense.weight\n",
      "2021-09-17 10:53:34,689 - INFO - allennlp.modules.token_embedders.embedding - Loading a model trained before embedding extension was implemented; pass an explicit vocab namespace if you want to extend the vocabulary.\n",
      "2021-09-17 10:53:34,690 - INFO - allennlp.modules.token_embedders.embedding - Loading a model trained before embedding extension was implemented; pass an explicit vocab namespace if you want to extend the vocabulary.\n",
      "2021-09-17 10:53:35,795 - INFO - allennlp.models.archival - removing temporary unarchived model dir at C:\\Users\\JOSHUA~1\\AppData\\Local\\Temp\\tmpzlz3qh1b\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "## SOME DOCUMENTATION\r\n",
    "# https://chairnerd.seatgeek.com/fuzzywuzzy-fuzzy-string-matching-in-python/\r\n",
    "# https://github.com/seatgeek/fuzzywuzzy\r\n",
    "def leaderAliasGenerator(leader_observation):\r\n",
    "    row = leader_observation\r\n",
    "    full_name_tuple = (row.econ_style_first, row.econ_style_last)\r\n",
    "    full_name = str.title(' '.join(full_name_tuple))\r\n",
    "\r\n",
    "    title_last_pref_tuple = (row.hos_title, row.econ_style_last)\r\n",
    "    title_last_pref = str.title(' '.join(title_last_pref_tuple))\r\n",
    "\r\n",
    "\r\n",
    "    \r\n",
    "    # Adding gendered honorifics\r\n",
    "    if row.gender == 1:\r\n",
    "        hon_list = []\r\n",
    "        hon = \"Mr\"\r\n",
    "        hon_last = str.title(' '.join([hon, row.econ_style_last]))\r\n",
    "        hon_list.append(hon_last)\r\n",
    "    else:\r\n",
    "        hon_1 = \"Ms\"\r\n",
    "        hon_last_1 = str.title(' '.join([hon_1, row.econ_style_last]))\r\n",
    "        hon_2 = \"Miss\"\r\n",
    "        hon_last_2 = str.title(' '.join([hon_2, row.econ_style_last]))\r\n",
    "        hon_3 = \"Mrs\"\r\n",
    "        hon_last_3 = str.title(' '.join([hon_3, row.econ_style_last]))\r\n",
    "\r\n",
    "\r\n",
    "    choices = [full_name, title_last_pref] + hon_list\r\n",
    "\r\n",
    "\r\n",
    "    #Adding other/type of honorific if necessary/available\r\n",
    "    if type(row.hos_title_other) != float:\r\n",
    "        title_last_alt_tuple = (row.hos_title_other, row.econ_style_last)\r\n",
    "        title_last_alt = str.title(' '.join(title_last_alt_tuple))\r\n",
    "        \r\n",
    "        choices.insert(2, title_last_alt)\r\n",
    "\r\n",
    "    # Adding Economist-style alias if necessary/available\r\n",
    "    if type(row.econ_style_alias) != float:\r\n",
    "        alias = row.econ_style_alias\r\n",
    "        econ_alias = str.title(alias)\r\n",
    "\r\n",
    "        choices.insert(2, econ_alias)\r\n",
    "\r\n",
    "    return choices\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def fuzzy_leader_search(plain_text, choices): \r\n",
    "    honorifics = [\"Mr\", \"Ms\", \"Miss\", \"Mrs\"]\r\n",
    "    topSetMatch = process.extract(plain_text, choices, scorer=fuzz.token_set_ratio)\r\n",
    "\r\n",
    "    for alias in topSetMatch:\r\n",
    "        # IF WE ARE CONSIDERING Mr/Ms _____ AS THE CANDIDATE HONORIFIC RAISE THE THRESHOLD FOR MATCH TO 100 (BASICALLY PERFECT MATCH)\r\n",
    "        if alias[0].split()[0] in honorifics:\r\n",
    "            if alias[1] == 100:\r\n",
    "                return True\r\n",
    "            else:\r\n",
    "                continue\r\n",
    "        # WE ARE CONSIDERING A FULL NAME OR A TILE NAME Like President ____\r\n",
    "        else:\r\n",
    "            if alias[1] >= 90:\r\n",
    "                return True\r\n",
    "\r\n",
    "    return False \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "def replaceCoref(name, clusters, cluster_interest_index, document, tokenized_df):\r\n",
    "    name_pos = name + \"\\'s\"\r\n",
    "    name_pos = name_pos.split()\r\n",
    "    name = name.split()\r\n",
    "\r\n",
    "    # print(cluster_interest_index)\r\n",
    "    base_cluster = clusters[cluster_interest_index]\r\n",
    "    # print(base_cluster)\r\n",
    "    \r\n",
    "    #Coreferences are replaced in reverse order so that we as we replace references that occur towards the end of the article we don't have to worry about how new string/list length is affected. That is, the indices identified in base_cluster are still valid.\r\n",
    "    rev_cluster  = sorted(base_cluster, key = lambda x: x[0], reverse = True)\r\n",
    "    new_doc_list = document\r\n",
    "\r\n",
    "    df = tokenized_df\r\n",
    "    # print(\"REPLACING WITH: \" + str(name) + \" (or possessive)\")\r\n",
    "    for index_pair in rev_cluster:\r\n",
    "        start_index = index_pair[0]\r\n",
    "        stop_index = index_pair[1]+1\r\n",
    "        # print(\"REPLACING: \" + str(new_doc_list[start_index:stop_index]))\r\n",
    "\r\n",
    "        # Replacing one element (i.e. pronouns/possessives)\r\n",
    "        if start_index == stop_index:\r\n",
    "            if containsPossessive(df, start_index, stop_index) == True:\r\n",
    "                new_doc_list[start_index:stop_index] = name_pos\r\n",
    "            else:\r\n",
    "                new_doc_list[start_index:stop_index] = name\r\n",
    "            new_doc_list.pop(start_index+2)\r\n",
    "        # Replacing two or more elements\r\n",
    "        else:\r\n",
    "            if containsPossessive(df, start_index, stop_index) == True:\r\n",
    "                new_doc_list[start_index:stop_index] = name_pos\r\n",
    "            else:\r\n",
    "                new_doc_list[start_index:stop_index] = name\r\n",
    "\r\n",
    "    # print(new_doc_list)\r\n",
    "    return new_doc_list"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def containsPossessive(df, start_index, stop_index):\r\n",
    "    possessive_tags = ['POS', 'PRP$']\r\n",
    "    cluster_tags = df['tag'].iloc[start_index:stop_index]\r\n",
    "    # .isdisjoint returns true if the two sets are disjoin (i.e. do not have any elements interesecting (i.e. does not contain a POS or PRP$)). So negate to return True if \"NOT DISJOINT\" (CONTAINS POS/PRP$)\r\n",
    "    if not set(possessive_tags).isdisjoint(set(cluster_tags)):\r\n",
    "        return True\r\n",
    "    else:\r\n",
    "        return False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "def identifyMainCluster(clusters, name, document):\r\n",
    "    clusters = clusters\r\n",
    "    aliases = name\r\n",
    "\r\n",
    "\r\n",
    "    for cluster in clusters:\r\n",
    "        for index_pair in cluster:\r\n",
    "            start_index = index_pair[0]\r\n",
    "            stop_index = index_pair[1]+1\r\n",
    "            cluster_as_string = ' '.join(document[start_index:stop_index])\r\n",
    "\r\n",
    "            top_set_match = process.extract(cluster_as_string, aliases)\r\n",
    "            fuzz_match_results = zip(*top_set_match)\r\n",
    "            fuzz_match_res_unzipped = list(fuzz_match_results)\r\n",
    "            scores = fuzz_match_res_unzipped[1]\r\n",
    "\r\n",
    "            if max(scores) >= 90:\r\n",
    "                cluster_index = clusters.index(cluster)\r\n",
    "                # print(\"CLUSTER AS STRING: \" + cluster_as_string)\r\n",
    "                # print(\"FUZZY MATCH SCORES: \" + str(top_set_match))\r\n",
    "                # print(\"CLUSTER: \" + str(cluster))\r\n",
    "                # print(\"INDEX OF THAT CLUSTER\" + str(cluster_index))\r\n",
    "                return cluster_index\r\n",
    "\r\n",
    "    # There may be instances in which the leader is mentioned but not in a fashion that is sufficiently important to be picked up as an entity by the model. These are usually in instances where the leader is only an object in the sentence and never becomes a subject. In those instances no replacement takes place.\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def termLimitChecker(date, start, end):\r\n",
    "\r\n",
    "    if start <= date <= end: \r\n",
    "        return \"IN TERM\"\r\n",
    "    elif date < start:\r\n",
    "        return \"PRE TERM\"\r\n",
    "    else:\r\n",
    "        return \"POST TERM\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "date_index_reference = 'issue_sheet_index.csv'\r\n",
    "# chunksize = 1000\r\n",
    "date_format = '%d-%b-%y'\r\n",
    "custom_date_parser = lambda x: dt.strptime(x, date_format)\r\n",
    "\r\n",
    "formatted_csv_path = '../00_The_Economist_Scraper/formatted_csvs/'\r\n",
    "formatted_csv_stub = 'formatted_sub_article_text'\r\n",
    "suffix = '.csv'\r\n",
    "\r\n",
    "if not os.path.isfile(date_index_reference):\r\n",
    "    print('date index needs to be instantiated, proceeding to do that')\r\n",
    "    #Initialize the index df\r\n",
    "    index_df = pd.DataFrame([], columns=['date_issue', 'sheet_path', 'sheet_num'])    \r\n",
    "\r\n",
    "    # GOING THROUGH EACH FORMATTED CSV\r\n",
    "    for sub_csv_index in tqdm(range(0,124)):\r\n",
    "        read_path = formatted_csv_path + formatted_csv_stub + str(sub_csv_index) + suffix\r\n",
    "        temp_df =  pd.read_csv(read_path, parse_dates=['date'], date_parser=custom_date_parser)\r\n",
    "\r\n",
    "        # Identifying unique dates\r\n",
    "        temp_df = temp_df.drop_duplicates(subset=['date'], keep='first')\r\n",
    "        temp_df = temp_df['date']\r\n",
    "\r\n",
    "        temp_index = pd.DataFrame([], columns=['date_issue', 'sheet_path', 'sheet_num'])\r\n",
    "\r\n",
    "        # Pulling out the info of interest \r\n",
    "        for issue_row in temp_df.index.tolist():\r\n",
    "            row_obs = temp_df.loc[issue_row]\r\n",
    "            # recall that temp_df is now just a single column of 'date\r\n",
    "            temp_index.loc[issue_row, 'date_issue'] = temp_df.loc[issue_row].date()\r\n",
    "            temp_index.loc[issue_row, 'sheet_path'] = formatted_csv_path + formatted_csv_stub + str(sub_csv_index) + suffix\r\n",
    "            temp_index.loc[issue_row, 'sheet_num'] = sub_csv_index\r\n",
    "        ### REMEMBER THAT A DATE MIGHT APPEAR IN/CROSS OVER MORE THAN ONE SHEET\r\n",
    "        # Need to concat and reset indices because first instances of different issues may appear on the same row (i.e. \"index\" of temp_df) of different sheets. Need to do this to avoid conflicts\r\n",
    "        index_df = pd.concat([index_df, temp_index], ignore_index=True)\r\n",
    "        index_df.reset_index(drop=True, inplace=True)\r\n",
    "        index_df['date_issue'] = pd.to_datetime(index_df['date_issue'])\r\n",
    "\r\n",
    "    index_df.to_csv(date_index_reference, index=False)\r\n",
    "        \r\n",
    "else:\r\n",
    "    print('Issues are already indexed for their dates, carry on')\r\n",
    "    index_df = pd.read_csv(date_index_reference)\r\n",
    "    index_df['date_issue'] = pd.to_datetime(index_df['date_issue'])\r\n",
    "\r\n",
    "print(index_df.head(5))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "### READING IN LEADER TERM DATA\r\n",
    "leader_term_name_df = pd.read_csv('all_leaders_econ_styling.csv', encoding='latin1')\r\n",
    "leader_term_name_df = leader_term_name_df.drop_duplicates(subset='leadid')\r\n",
    "\r\n",
    "\r\n",
    "leader_term_name_df['term_start'] = dt.now\r\n",
    "leader_term_name_df['term_end'] =dt.now\r\n",
    "\r\n",
    "# leader_term_name_df\r\n",
    "for index in tqdm(leader_term_name_df.index.tolist()):\r\n",
    "    # FORMAT: start = dt(year, month, day)\r\n",
    "    leader_term_name_df.loc[index, 'term_start'] = dt(leader_term_name_df.loc[index, 'start_year'], leader_term_name_df.loc[index, 'start_month'], leader_term_name_df.loc[index, 'start_date'])\r\n",
    "    \r\n",
    "    # Push to the end of the month as far as possible (accounting for leap years)\r\n",
    "    # Note that we are pushing the end of the term out 6 months anyway (in case we miss an issue printed on the 29th-31st)\r\n",
    "    leader_term_name_df.loc[index, 'term_end'] = dt(leader_term_name_df.loc[index, 'end_year'], leader_term_name_df.loc[index, 'end_month'], 28)\r\n",
    "\r\n",
    "# print(leader_term_name_df.head(5))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 560/560 [00:00<00:00, 2348.86it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# MATCHING TERM-WINDOWS (term length +/- 6 months) WITH ECONOMIST ISSUE DATES\r\n",
    "# We then pair this with the dat_index_reference.csv to figure out which chunks of formatted_compiled_articles.csv we should read\r\n",
    "six_month_margin = relativedelta(months = 6)\r\n",
    "\r\n",
    "leaders_windows_indices_df = leader_term_name_df\r\n",
    "\r\n",
    "# Constructing the 6 month window around the term start\r\n",
    "leaders_windows_indices_df = leaders_windows_indices_df.assign(leader_aprox_starts = lambda df: df.term_start - six_month_margin)\r\n",
    "leaders_windows_indices_df = leaders_windows_indices_df.assign(leader_aprox_ends = lambda df: df.term_end + six_month_margin)\r\n",
    "leaders_windows_indices_df['leader_aprox_starts'] = pd.to_datetime(leaders_windows_indices_df['leader_aprox_starts'])\r\n",
    "\r\n",
    "# Merge window-start and window-end dates with the \"nearest\" (FORWARD OR BACKWARD) Economist issue date.\r\n",
    "# Read in that issue's starting row/index\r\n",
    "# PRE-TERM\r\n",
    "leaders_windows_indices_df = leaders_windows_indices_df.sort_values(by=['leader_aprox_starts'])\r\n",
    "leaders_windows_indices_df = pd.merge_asof(left=leaders_windows_indices_df, right=index_df, left_on='leader_aprox_starts', right_on='date_issue', direction='nearest')\r\n",
    "leaders_windows_indices_df = leaders_windows_indices_df.rename(columns={'date_issue' : 'date_start_issue', 'sheet_path' : 'start_sheet_path', 'sheet_num' : 'start_sheet_num'})\r\n",
    "\r\n",
    "# POST-TERM\r\n",
    "leaders_windows_indices_df = leaders_windows_indices_df.sort_values(by=['leader_aprox_ends'])\r\n",
    "leaders_windows_indices_df = pd.merge_asof(left=leaders_windows_indices_df, right=index_df, left_on='leader_aprox_ends', right_on='date_issue', direction='nearest')\r\n",
    "leaders_windows_indices_df = leaders_windows_indices_df.rename(columns={'date_issue': 'date_end_issue', 'sheet_path': 'end_sheet_path', 'sheet_num' : 'end_sheet_num'})\r\n",
    "\r\n",
    "################################################\r\n",
    "# Add in titles and adjectives\r\n",
    "################################################\r\n",
    "adjectives_df = pd.read_csv('national_titles_adjectives.csv').drop(columns=['country'])\r\n",
    "leaders_windows_indices_df = pd.merge(leaders_windows_indices_df, adjectives_df, how='left', on='ccode')\r\n",
    "\r\n",
    "\r\n",
    "print(len(leader_term_name_df))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "560\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "LEADER_BATCH_SIZE  = 2\r\n",
    "\r\n",
    "# Check leaders we have already done\r\n",
    "resolved_leaders_df = pd.read_csv('resolved_leader_tracker_temp.csv')\r\n",
    "\r\n",
    "non_resolved_leaders_df = pd.merge(leaders_windows_indices_df, resolved_leaders_df, how='outer', on='leadid',indicator=True).query('_merge == \"left_only\"').drop(columns=['_merge'])\r\n",
    "\r\n",
    "\r\n",
    "# leader_batch_sample = non_resolved_leaders_df.sample(n=LEADER_BATCH_SIZE)\r\n",
    "# leader_batch_sample = non_resolved_leaders_df.loc[non_resolved_leaders_df.leadid in [\"A2.9-8200\", \"A2.9-4234\"]]\r\n",
    "leader_batch_sample = non_resolved_leaders_df.loc[non_resolved_leaders_df.leadid == \"A2.9-4231\"]\r\n",
    "\r\n",
    "# Run this loop for every leader in this batch\r\n",
    "for index in leader_batch_sample.index.tolist():\r\n",
    "    \r\n",
    "    term_info = leader_batch_sample.loc[index, :]\r\n",
    "    name = term_info.econ_style_last.replace('.','')\r\n",
    "    name = name.replace(' ', '')\r\n",
    "    leaderid = term_info.leadid.replace('.','')\r\n",
    "    leader_gender_hon = term_info.gender\r\n",
    "    start_sheet = term_info.start_sheet_num\r\n",
    "    end_sheet = term_info.end_sheet_num\r\n",
    "    # start_at_0 = True if term_info.issue_starting_row==0 else False\r\n",
    "\r\n",
    "    # Instantiate a list which will contain DFs for future concatenation\r\n",
    "    chunk_list = []\r\n",
    "\r\n",
    "    # These are the columns that we are going to get by default (make sure to title the new df with these incase we don't read row 0 of the .csv)\r\n",
    "    # col_names = ['date', 'link', 'text']\r\n",
    "    print(start_sheet, end_sheet)\r\n",
    "    print('loading ' + str(end_sheet - end_sheet + 1) + ' sheets')\r\n",
    "\r\n",
    "\r\n",
    "    ##### NEED TO FIX THIS LINE RANGE\r\n",
    "    for sheet_num in range(start_sheet, start_sheet+1):\r\n",
    "        chunk_path = formatted_csv_path + formatted_csv_stub + str(sheet_num) + suffix\r\n",
    "        chunk_df = pd.read_csv(chunk_path, parse_dates=['date'], date_parser=custom_date_parser)\r\n",
    "        chunk_list.append(chunk_df)\r\n",
    "\r\n",
    "    df = pd.concat(chunk_list, ignore_index=True)\r\n",
    "\r\n",
    "    # Add some extra meta-data to this article-level observation\r\n",
    "    df['ccode'] = term_info.ccode\r\n",
    "    df['country'] = term_info.country\r\n",
    "    df['resolved_text'] = ''\r\n",
    "    df['pre_in_post_term'] = ''\r\n",
    "    df['coreference_resolved_ind'] = False\r\n",
    "    df[name] = False\r\n",
    "\r\n",
    "    # Coerce some of the df[name] observations to True(using a fuzzy match) to identify the subset of all articles in this term +/-6 month window that actually mention the leader\r\n",
    "    leader_alias_choices = leaderAliasGenerator(term_info)\r\n",
    "    print('fuzzy searching on {} rows'.format(len(df)))\r\n",
    "    print(leader_alias_choices)\r\n",
    "    for leader_dummy_idx in tqdm(df.index.tolist(), desc='FUZZY MATCH/SEARCH'):\r\n",
    "        string_to_search = df.loc[leader_dummy_idx, 'text']\r\n",
    "        df.loc[leader_dummy_idx, name] = fuzzy_leader_search(string_to_search, leader_alias_choices)\r\n",
    "\r\n",
    "    df = df[df[name] == True]\r\n",
    "    df = df.head(8)\r\n",
    "\r\n",
    "\r\n",
    "    print(\"number of articles identified for \" + name + \": \" + str(len(df)))\r\n",
    "\r\n",
    "\r\n",
    "    startTime = dt.now()\r\n",
    "    # Do coreference resolution on that subset of articles that mention the leader\r\n",
    "    for row_index in tqdm(df.index.tolist(), desc=name):\r\n",
    "        try:\r\n",
    "            pre_resolve_text = df.loc[row_index, 'text']\r\n",
    "            pred_obj = predictor.predict(document = pre_resolve_text)\r\n",
    "\r\n",
    "            spacy_df = pd.DataFrame([], columns = ['text', 'lemma', 'pos', 'tag', 'dep'])\r\n",
    "\r\n",
    "            document_clusters = pred_obj['clusters']    \r\n",
    "            document_list = pred_obj['document']\r\n",
    "            spacy_doc = nlp(pre_resolve_text) \r\n",
    "\r\n",
    "            leader_name = leader_alias_choices[0]\r\n",
    "\r\n",
    "            for token in spacy_doc:\r\n",
    "                tok_observation = [token.text, token.lemma_, token.pos_, token.tag_, token.dep_]\r\n",
    "                spacy_df.loc[len(spacy_df)] = tok_observation\r\n",
    "\r\n",
    "            cluster_of_interest = identifyMainCluster(document_clusters, leader_alias_choices, document_list)\r\n",
    "            print(leader_name)\r\n",
    "\r\n",
    "            replaced = replaceCoref(leader_name, document_clusters, cluster_of_interest, document_list, spacy_df)\r\n",
    "\r\n",
    "            df.loc[row_index, 'resolved_text'] = ' '.join(replaced)\r\n",
    "            df.loc[row_index, 'coreference_resolved_ind'] = True\r\n",
    "            # print('successfully replaced coreferences')\r\n",
    "\r\n",
    "        except Exception as e:\r\n",
    "            print('excepting')\r\n",
    "            print(e)\r\n",
    "            df.loc[row_index, 'resolved_text'] = df.loc[row_index, 'text']\r\n",
    "            continue\r\n",
    "\r\n",
    "        df.loc[row_index, 'pre_in_post_term'] = termLimitChecker(df.loc[row_index, 'date'], term_info.term_start, term_info.term_end)\r\n",
    "    \r\n",
    "    \r\n",
    "    df.to_csv('leader_resolved/' + name + '_resolved' + leaderid + '.csv', index=False)\r\n",
    "    print('Time to coresolve XXX observations: {}'.format(dt.now() - startTime))\r\n",
    "    resolved_leaders_df.loc[len(resolved_leaders_df)]=[term_info.leader_x, term_info.leadid, 'RESOLVED']\r\n",
    "\r\n",
    "    resolved_leaders_df.to_csv('resolved_leader_tracker_temp.csv', index=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "15 54\n",
      "loading 40 sheets\n",
      "fuzzy searching on 999 rows\n",
      "['Jose Maria Aznar', 'Prime Minister Aznar', 'Mr Aznar']\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "FUZZY MATCH/SEARCH: 100%|██████████| 999/999 [00:01<00:00, 786.49it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "number of articles identified for aznar: 1\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "aznar: 100%|██████████| 1/1 [00:35<00:00, 35.90s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CLUSTER AS STRING: Jose Maria Aznar , himself a relative lad of 42\n",
      "FUZZY MATCH SCORES: [('Jose Maria Aznar', 90), ('Prime Minister Aznar', 86), ('Mr Aznar', 86)]\n",
      "CLUSTER: [[33, 34], [52, 54], [65, 65], [69, 76], [91, 91], [139, 140], [183, 185], [332, 333], [376, 378], [381, 381], [383, 383], [431, 433], [437, 437], [482, 483], [483, 483], [491, 491], [497, 498], [506, 506], [512, 512], [534, 534], [537, 537], [567, 567], [590, 590], [603, 604], [634, 645], [642, 642], [650, 650], [747, 749], [765, 765], [805, 806], [834, 834], [840, 841], [849, 849], [858, 858], [999, 1001], [1009, 1009], [1062, 1063], [1071, 1071], [1888, 1897], [1899, 1899], [2142, 2143], [2815, 2816], [2921, 2922], [2932, 2932], [3115, 3117], [3149, 3150], [3236, 3238], [3290, 3316], [3301, 3301], [3328, 3329], [3336, 3342], [3345, 3346], [3355, 3355], [3362, 3362], [3373, 3373], [3384, 3384], [3387, 3387], [3391, 3391], [3395, 3395], [3408, 3408], [3413, 3413], [3434, 3434], [3457, 3458], [3470, 3470], [3489, 3489], [3495, 3495], [3536, 3537], [3573, 3573], [3588, 3588], [3596, 3596], [3602, 3602], [3612, 3612], [3622, 3622], [3644, 3644], [3650, 3650], [3656, 3657], [3687, 3688], [3702, 3702], [3705, 3706], [3708, 3708], [3712, 3713], [3780, 3782], [3804, 3806]]\n",
      "INDEX OF THAT CLUSTER2\n",
      "Jose Maria Aznar\n",
      "2\n",
      "REPLACING WITH: ['Jose', 'Maria', 'Aznar'] (or possessive)\n",
      "REPLACING: ['post', '-', 'Gonzalez']\n",
      "REPLACING: ['Mr', 'Gonzalez', \"'s\"]\n",
      "REPLACING: ['Mr', 'Gonzalez']\n",
      "REPLACING: ['his']\n",
      "REPLACING: ['Mr', 'Gonzalez']\n",
      "REPLACING: ['he']\n",
      "REPLACING: ['Mr', 'Aznar']\n",
      "REPLACING: ['Mr', 'Aznar']\n",
      "REPLACING: ['he']\n",
      "REPLACING: ['his']\n",
      "REPLACING: ['he']\n",
      "REPLACING: ['I']\n",
      "REPLACING: ['he']\n",
      "REPLACING: ['he']\n",
      "REPLACING: ['he']\n",
      "REPLACING: ['he']\n",
      "REPLACING: ['Mr', 'Aznar']\n",
      "REPLACING: ['he']\n",
      "REPLACING: ['he']\n",
      "REPLACING: ['he']\n",
      "REPLACING: ['Mr', 'Aznar']\n",
      "REPLACING: ['his']\n",
      "REPLACING: ['he']\n",
      "REPLACING: ['his']\n",
      "REPLACING: ['he']\n",
      "REPLACING: ['his']\n",
      "REPLACING: ['his']\n",
      "REPLACING: ['he']\n",
      "REPLACING: ['him']\n",
      "REPLACING: ['His']\n",
      "REPLACING: ['He']\n",
      "REPLACING: ['Mr', 'Aznar']\n",
      "REPLACING: ['this', 'unphotogenic', ',', 'seemingly', 'boring', 'tax', 'lawyer']\n",
      "REPLACING: ['Mr', 'Gonzalez']\n",
      "REPLACING: ['he']\n",
      "REPLACING: ['the', 'apparently', 'dull', 'and', 'cautious', 'Mr', 'Aznar', ',', 'solidly', 'unspectacular', 'when', 'Jose', 'Maria', 'Aznar', 'was', 'head', 'of', 'the', 'province', 'of', 'Castile', '-', 'Leon', 'before', 'taking', 'over', 'the']\n",
      "REPLACING: ['Mr', 'Gonzalez', \"'s\"]\n",
      "REPLACING: ['Mr', 'Gonzalez']\n",
      "REPLACING: ['Mr', 'Aznar', \"'s\"]\n",
      "REPLACING: ['him']\n",
      "REPLACING: ['Mr', 'Aznar']\n",
      "REPLACING: ['Mr', 'Aznar']\n",
      "REPLACING: ['Mr', 'Gonzalez']\n",
      "REPLACING: ['His']\n",
      "REPLACING: ['Jose', 'Maria', 'Aznar', ',', 'himself', 'a', 'relative', 'lad', 'of', '42']\n",
      "REPLACING: ['He']\n",
      "REPLACING: ['Mr', 'Gonzalez']\n",
      "REPLACING: ['He']\n",
      "REPLACING: ['Mr', 'Gonzalez', \"'s\"]\n",
      "REPLACING: ['His']\n",
      "REPLACING: ['his']\n",
      "REPLACING: ['Mr', 'Gonzalez']\n",
      "REPLACING: ['him']\n",
      "REPLACING: ['Mr', 'Gonzalez']\n",
      "REPLACING: ['him']\n",
      "REPLACING: ['Mr', 'Gonzalez', \"'s\"]\n",
      "REPLACING: ['him']\n",
      "REPLACING: ['he']\n",
      "REPLACING: ['Mr', 'Gonzalez', ',', 'a', 'lad', 'of', '40', 'when', 'Jose', 'Maria', 'Aznar', 'assumed']\n",
      "REPLACING: ['Mr', 'Gonzalez']\n",
      "REPLACING: ['his']\n",
      "REPLACING: ['his']\n",
      "REPLACING: ['he']\n",
      "REPLACING: ['His']\n",
      "REPLACING: ['His']\n",
      "REPLACING: ['his']\n",
      "REPLACING: ['Mr', 'Gonzalez']\n",
      "REPLACING: ['his']\n",
      "REPLACING: ['himself']\n",
      "REPLACING: ['he', 'Jose']\n",
      "REPLACING: ['he']\n",
      "REPLACING: ['Mr', 'Gonzalez', 'himself']\n",
      "REPLACING: ['he']\n",
      "REPLACING: ['He']\n",
      "REPLACING: ['Mr', 'Gonzalez', \"'s\"]\n",
      "REPLACING: ['Mr', 'Gonzalez']\n",
      "REPLACING: ['Mr', 'Gonzalez', \"'s\"]\n",
      "REPLACING: ['Mr', 'Gonzalez']\n",
      "REPLACING: ['he']\n",
      "REPLACING: ['The', 'prime', 'minister', ',', 'battered', 'and', 'weary', ',']\n",
      "REPLACING: ['he']\n",
      "REPLACING: ['Mr', 'Gonzalez', \"'s\"]\n",
      "REPLACING: ['Felipe', 'Gonzalez']\n",
      "successfully replaced coreferences\n",
      "Time to coresolve XXX observations: 0:00:35.932813\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('pandastest': conda)"
  },
  "interpreter": {
   "hash": "c5e5d7fb3d81e909d19c7041dfc7fdf19de476fcee5121b32a71cede18f9d3ba"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}